{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "student data_using_causalnex.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbX7LXgXyYdM"
      },
      "source": [
        "# Install causalnex, pydotplus and required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_dtfGPl7gon"
      },
      "source": [
        "!pip install causalnex\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6Y5U11hCE-Y"
      },
      "source": [
        "pip install \"causalnex[all]\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEGw-3E1kv7N"
      },
      "source": [
        "!pip install pydotplus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaQJmJXzpaQB"
      },
      "source": [
        "!pip install -q pydot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0t51aaNtXOD"
      },
      "source": [
        "!apt install libgraphviz-dev\n",
        "!pip install pygraphviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVyF2FRhBmMN"
      },
      "source": [
        "!pip install pygraphviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgqwhEnlCgjb"
      },
      "source": [
        "#sudo apt-get install python-pip python-virtualenv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQKtEAswtPDu"
      },
      "source": [
        "#!pip install graphviz !apt-get install graphviz\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ir2KrcqT76K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVOzNGf_TmPk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EysDkHMyi5U"
      },
      "source": [
        "# Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWdIT8JX7m7D"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpaLu8WF76Wl"
      },
      "source": [
        "data=pd.read_csv('student-por.csv',sep=';')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQcF5LURoawA"
      },
      "source": [
        "drop_col = ['school','sex','age','Mjob', 'Fjob','reason','guardian']\n",
        "data = data.drop(columns=drop_col)\n",
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaCk8Shv6XLv"
      },
      "source": [
        "import numpy as np\n",
        "struct_data = data.copy()\n",
        "\n",
        "non_numeric_columns = list(struct_data.select_dtypes(exclude=[np.number]).columns)\n",
        "print(non_numeric_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9zPfY5mohqe"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "for col in non_numeric_columns:\n",
        "    struct_data[col] = le.fit_transform(struct_data[col])\n",
        "\n",
        "struct_data.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_EBpGsYyuCH"
      },
      "source": [
        "# Applying the NOTEARS algorithm to learn the structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUAUZgfk8MYJ"
      },
      "source": [
        "\n",
        "# silence warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "from causalnex.structure.notears import from_pandas\n",
        "sm = from_pandas(struct_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEkc4xTZy2f3"
      },
      "source": [
        "#### visualise the learned StructureModel using the plot function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2jZBR0e8WqL"
      },
      "source": [
        "from IPython.display import Image\n",
        "from causalnex.plots import plot_structure, NODE_STYLE, EDGE_STYLE\n",
        "\n",
        "# viz = plot_structure(\n",
        "#     sm,\n",
        "#     graph_attributes={\"scale\": \"0.8\"},\n",
        "#     all_node_attributes=NODE_STYLE.WEAK,\n",
        "#     all_edge_attributes=EDGE_STYLE.WEAK)\n",
        "# Image(viz.draw(format='jpg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnB2MULHzUdr"
      },
      "source": [
        "####The reason why we have a fully connected graph here is we havenâ€™t applied thresholding to the weaker edges. Thresholding can be applied either by specifying the value for the parameter w_threshold in from_pandas, or we can remove the edges by calling the structure model function, remove_edges_below_threshold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJmSmXZz8bEd"
      },
      "source": [
        "sm.remove_edges_below_threshold(0.8)\n",
        "viz = plot_structure(\n",
        "    sm,\n",
        "    graph_attributes={\"scale\": \"0.5\"},\n",
        "    all_node_attributes=NODE_STYLE.WEAK,\n",
        "    all_edge_attributes=EDGE_STYLE.WEAK)\n",
        "Image(viz.draw(format='png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1DK7nE-cNaK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLu6vi7mcRH8"
      },
      "source": [
        "# Modifying the Structure\n",
        "To correct erroneous relationships, we can incorporate domain knowledge into the model after structure learning. We can modify the structure model through adding and deleting the edges. For example, we can add and remove edges as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E_MXro-6zkl"
      },
      "source": [
        "sm = from_pandas(struct_data, tabu_edges=[(\"higher\", \"Medu\")], w_threshold=0.8)\n",
        "viz = plot_structure(\n",
        "    sm,\n",
        "    graph_attributes={\"scale\": \"0.5\"},\n",
        "    all_node_attributes=NODE_STYLE.WEAK,\n",
        "    all_edge_attributes=EDGE_STYLE.WEAK)\n",
        "Image(viz.draw(format='png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR4PplIb6zoA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QfQU72YcNdm"
      },
      "source": [
        "# sm.add_edge(\"breast-quad\", \"Class\")\n",
        "# sm.add_edge('menopause','Class')\n",
        "\n",
        "sm.add_edge(\"failures\", \"G1\")\n",
        "sm.remove_edge(\"Pstatus\", \"G1\")\n",
        "sm.remove_edge(\"address\", \"G1\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6ViQq5ZyWge"
      },
      "source": [
        "viz = plot_structure(\n",
        "    sm,\n",
        "    graph_attributes={\"scale\": \"0.5\"},\n",
        "    all_node_attributes=NODE_STYLE.WEAK,\n",
        "    all_edge_attributes=EDGE_STYLE.WEAK)\n",
        "Image(viz.draw(format='png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6R0vTcDh9Js"
      },
      "source": [
        "#### We can now visualise our updated structure to confirm it looks reasonable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqJL7UIVh6LM"
      },
      "source": [
        "#### We can see there are two separate subgraphs here in the visualisation plot: Dalc->Walc and the other big subgraph. We can retrieve the largest subgraph easily by calling the StructureModel function get_largest_subgraph()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw_fh4-Ch1Vb"
      },
      "source": [
        "sm = sm.get_largest_subgraph()\n",
        "\n",
        "viz = plot_structure(\n",
        "    sm,\n",
        "    graph_attributes={\"scale\": \"0.5\"},\n",
        "    all_node_attributes=NODE_STYLE.WEAK,\n",
        "    all_edge_attributes=EDGE_STYLE.WEAK)\n",
        "Image(viz.draw(format='png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGHM8ZB1h1as"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBbpVqikiIb-"
      },
      "source": [
        "## After deciding on how the final structure model should look, we can instantiate a BayesianNetwork."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nwl5RRbdu01X"
      },
      "source": [
        "from causalnex.network import BayesianNetwork\n",
        "\n",
        "bn = BayesianNetwork(sm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqJRJkRpyDna"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMzCEqC4U-Xp"
      },
      "source": [
        "##### We are now ready to move on to learning the conditional probability distribution of different features in the BayesianNetwork."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNm3UET6jNN3"
      },
      "source": [
        "discretised_data = data.copy()\n",
        "\n",
        "data_vals = {col: data[col].unique() for col in data.columns}\n",
        "\n",
        "failures_map = {v: 'no-failure' if v == [0]\n",
        "            else 'have-failure' for v in data_vals['failures']}\n",
        "\n",
        "studytime_map = {v: 'short-studytime' if v in [1,2]\n",
        "                 else 'long-studytime' for v in data_vals['studytime']}\n",
        "\n",
        "discretised_data[\"failures\"] = discretised_data[\"failures\"].map(failures_map)\n",
        "discretised_data[\"studytime\"] = discretised_data[\"studytime\"].map(studytime_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozcTo628XA0D"
      },
      "source": [
        "from causalnex.discretiser import Discretiser\n",
        "\n",
        "discretised_data[\"absences\"] = Discretiser(method=\"fixed\",\n",
        "                          numeric_split_points=[1, 10]).transform(discretised_data[\"absences\"].values)\n",
        "\n",
        "discretised_data[\"G1\"] = Discretiser(method=\"fixed\",\n",
        "                          numeric_split_points=[10]).transform(discretised_data[\"G1\"].values)\n",
        "\n",
        "discretised_data[\"G2\"] = Discretiser(method=\"fixed\",\n",
        "                          numeric_split_points=[10]).transform(discretised_data[\"G2\"].values)\n",
        "\n",
        "discretised_data[\"G3\"] = Discretiser(method=\"fixed\",\n",
        "                          numeric_split_points=[10]).transform(discretised_data[\"G3\"].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QNdpQ9CXFsO"
      },
      "source": [
        "# Fitting the Conditional Distribution of the Bayesian Network\n",
        "### Preparing the Discretised Data\n",
        "Bayesian Networks in CausalNex support only discrete distributions. Any continuous features, or features with a large number of categories, should be discretised prior to fitting the Bayesian Network. Models containing variables with many possible values will typically be badly fit, and exhibit poor performance.\n",
        "\n",
        "For example, consider P(G2 | G1), where G1 and G2 have possible values 0 to 20. The discrete conditional probability distribution is therefore specified using 21x21 (441) possible combinations - most of which we will be unlikely to observe.\n",
        "\n",
        "CausalNex provides a few helper methods to make discretisation easier. Letâ€™s start by reducing the number of categories in some of the categorical features by combining similar values. We will make numeric features categorical by discretisation, and then give the buckets meaningful labels.\n",
        "\n",
        "# Cardinality of Categorical Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmomh0trYR8V"
      },
      "source": [
        "absences_map = {0: \"No-absence\", 1: \"Low-absence\", 2: \"High-absence\"}\n",
        "\n",
        "G1_map = {0: \"Fail\", 1: \"Pass\"}\n",
        "G2_map = {0: \"Fail\", 1: \"Pass\"}\n",
        "G3_map = {0: \"Fail\", 1: \"Pass\"}\n",
        "\n",
        "discretised_data[\"absences\"] = discretised_data[\"absences\"].map(absences_map)\n",
        "discretised_data[\"G1\"] = discretised_data[\"G1\"].map(G1_map)\n",
        "discretised_data[\"G2\"] = discretised_data[\"G2\"].map(G2_map)\n",
        "discretised_data[\"G3\"] = discretised_data[\"G3\"].map(G3_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYPG9-jgYSAL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugDkHCRxjPZP"
      },
      "source": [
        "## Train-Test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W75HxLj5jNUU"
      },
      "source": [
        "# Split 90% train and 10% test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(discretised_data, train_size=0.9, test_size=0.1, random_state=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkZuQEd9Y4MI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUMWRW7HY4k_"
      },
      "source": [
        "# Model Probability\n",
        "With the learnt structure model from earlier and the discretised data, we can now fit the probability distrbution of the Bayesian Network. The first step in this is specifying all of the states that each node can take. This can be done either from data, or providing a dictionary of node values. We use the full dataset here to avoid cases where states in our test set do not exist in the training set. For real-world applications, these states may need to be provided using the dictionary method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_lDE86LY-r2"
      },
      "source": [
        "bn = bn.fit_node_states(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB7vMgcWZBwL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Evhy0pXLZEh7"
      },
      "source": [
        "# Fit Conditional Probability Distributions\n",
        "The fit_cpds method of BayesianNetwork accepts a dataset to learn the conditional probablilty distributions (CPDs) of each node, along with a method of how to do this fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN1W0HWvjOWP"
      },
      "source": [
        "bn = bn.fit_cpds(train, method=\"BayesianEstimator\", bayes_prior=\"K2\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ueEGXa_ZKzB"
      },
      "source": [
        "#### once we have the CPDs, we can inspect them through the cpds property, which is a dictionary of node->cpd."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrPIMyvojUbH"
      },
      "source": [
        "bn.cpds[\"G1\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTWYgFbpZWUq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtnIpyaSZTuK"
      },
      "source": [
        "#### The CPD dictionaries are multi-indexed, and so the loc function can be a useful way to interact with them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB6GsTTBZS-A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPi43ojdZZT9"
      },
      "source": [
        "# Predict the State given the Input Data\n",
        "The predict method of BayesianNetwork allows us to make predictions based on the data using the learnt Bayesian Network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe0I21dyZZzG"
      },
      "source": [
        "discretised_data.loc[18, discretised_data.columns != 'G1']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ9aYhcSZh8_"
      },
      "source": [
        "predictions = bn.predict(discretised_data, \"G1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOq6TNeoZxjU"
      },
      "source": [
        "\n",
        "print('The prediction is \\'{prediction}\\''.format(prediction=predictions.loc[18, 'G1_prediction']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SV3jzgwZ2jU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfkkTu40Z7BB"
      },
      "source": [
        "#### The prediction by the Bayesian Network turns out to be a Fail. Letâ€™s compare this to the ground truth:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwIbPYzXZ7u-"
      },
      "source": [
        "print('The ground truth is \\'{truth}\\''.format(truth=discretised_data.loc[18, 'G1']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDzkY-J2aD4x"
      },
      "source": [
        "##### which turns out to be the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM7cnUpVaBNE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSkcJUr9aGk-"
      },
      "source": [
        "# Model Quality\n",
        "To evaluate the quality of the model that has been learned, CausalNex supports two main approaches: Classification Report and Reciever Operating Characteristics (ROC) / Area Under the ROC Curve (AUC). In this section each will be discussed.\n",
        "\n",
        "# Classification Report\n",
        "To obtain a classification report using a BN, we need to provide a test set, and the node we are trying to classify. The report will predict the target node for all rows in the test set, and evaluate how well those predictions are made."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq_d4KO5aIMZ"
      },
      "source": [
        "from causalnex.evaluation import classification_report\n",
        "classification_report(bn, test, \"G1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETFo-3GbaLgE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py3Dq_nQaSag"
      },
      "source": [
        "#### This report shows that the model we have defined is able to classify whether a person having breast cancer or not.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bKghSoUaapA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLpTX5pEac9a"
      },
      "source": [
        "# ROC / AUC\n",
        "Reciever Operating Characteristics (ROC), and the Area Under the ROC Curve (AUC) can be obtained using the roc_auc method within the CausalNex metrics module. Again, a test set and target node must be provided. The ROC curve is computed by micro-averaging predictions made across all states (classes) of the target node."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVwn8SuGad2D"
      },
      "source": [
        "from causalnex.evaluation import roc_auc\n",
        "roc, auc = roc_auc(bn, test, \"G1\")\n",
        "print(auc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "autbEXaOakqI"
      },
      "source": [
        "#### The AUC value for our model is good enough, giving us confidence in the performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTSKd0XUaoBe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elEk2PdBa2Bo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNc4Rfwma_HY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}